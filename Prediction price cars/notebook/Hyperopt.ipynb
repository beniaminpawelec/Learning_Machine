{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/11/8bbbb5edb78c40a2bd0f6b730e3dc0f29ffbaea9a59520eb9622951e9151/hyperopt-0.2.3-py3-none-any.whl (1.9MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\benia\\anaconda3\\lib\\site-packages (from hyperopt) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\benia\\anaconda3\\lib\\site-packages (from hyperopt) (1.12.0)\n",
      "Requirement already satisfied: future in c:\\users\\benia\\anaconda3\\lib\\site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\benia\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.5)\n",
      "Collecting networkx==2.2 (from hyperopt)\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\benia\\anaconda3\\lib\\site-packages (from hyperopt) (4.36.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\benia\\anaconda3\\lib\\site-packages (from hyperopt) (1.2.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\benia\\anaconda3\\lib\\site-packages (from networkx==2.2->hyperopt) (4.4.0)\n",
      "Building wheels for collected packages: networkx\n",
      "  Building wheel for networkx (setup.py): started\n",
      "  Building wheel for networkx (setup.py): finished with status 'done'\n",
      "  Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1527327 sha256=f6470d728907f177125b40de8ff60e4ffb92f0428e1b9c30c64a98913f12af35\n",
      "  Stored in directory: C:\\Users\\benia\\AppData\\Local\\pip\\Cache\\wheels\\68\\f8\\29\\b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91\n",
      "Successfully built networkx\n",
      "Installing collected packages: networkx, hyperopt\n",
      "  Found existing installation: networkx 2.3\n",
      "    Uninstalling networkx-2.3:\n",
      "      Successfully uninstalled networkx-2.3\n",
      "Successfully installed hyperopt-0.2.3 networkx-2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp,fmin,tpe,STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benia\\Desktop\\Machine_Learning\\Prediction price cars\\data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('car.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUFFIX_CAT = \"_cat\"\n",
    "for feat in df.columns:\n",
    "    if isinstance(df[feat][0],list): continue\n",
    "    \n",
    "    factorized_values = df[feat].factorize()[0]\n",
    "    \n",
    "    if SUFFIX_CAT in feat:\n",
    "        df[feat] = factorized_values\n",
    "    else:\n",
    "        df[feat + SUFFIX_CAT] = factorized_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats = [x for x in df.columns if SUFFIX_CAT in x]\n",
    "cat_feats = [x for x in cat_feats if 'price' not in x]\n",
    "len(cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model , feats):\n",
    "    X = df[feats].values\n",
    "    y = df[\"price_value\"].values\n",
    "    \n",
    "    scores = cross_val_score(model,X,y,cv=3,scoring=\"neg_mean_absolute_error\")\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['param_rok-produkcji'] = df['param_rok-produkcji'].map(lambda x: -1 if str(x)== \"None\" else int(x))\n",
    "df['param_moc']= df['param_moc'].map(lambda x: -1 if str(x)== \"None\" else int(x.split(' ')[0]))\n",
    "df['param_pojemność-skokowa']= df['param_pojemność-skokowa'].map(lambda x: -1 if str(x)== \"None\" else int(str(x).split('cm')[0].replace(' ','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9618.08167109244, 79.8982870999676)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats =['param_napęd_cat','param_rok-produkcji','param_stan_cat','param_faktura-vat_cat','param_moc','param_skrzynia-biegów_cat','feature_kamera-cofania_cat','param_marka-pojazdu_cat','param_typ_cat','param_pojemność-skokowa','feature_wspomaganie-kierownicy_cat','seller_name_cat','param_wersja_cat','param_model-pojazdu_cat','feature_światła-led_cat','feature_asystent-pasa-ruchu_cat','param_kod-silnika_cat','feature_system-start-stop_cat','feature_regulowane-zawieszenie_cat','feature_łopatki-zmiany-biegów_cat']\n",
    "run_model(xgb.XGBRegressor(**xgb_params),feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params={\n",
    "    'max_depth':5,\n",
    "    'n_estimators':50,\n",
    "    'learning_rate':0.1,\n",
    "    'seed':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.15000000000000002, 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.75}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'max_depth': 13, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.55, 'learning_rate': 0.25, 'max_depth': 13, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.25, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 12, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.15000000000000002, 'max_depth': 14, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.05, 'max_depth': 12, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.75}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 12, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.25, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 15, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.55, 'learning_rate': 0.15000000000000002, 'max_depth': 8, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.55, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.15000000000000002, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.05, 'max_depth': 13, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 1.0}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 12, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.15000000000000002, 'max_depth': 13, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.65, 'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.65, 'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.65, 'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "100%|██████████████████████████████████████████████████| 25/25 [06:31<00:00, 15.64s/trial, best loss: 9618.08167109244]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.75,\n",
       " 'learning_rate': 1,\n",
       " 'max_depth': 6,\n",
       " 'subsample': 0.55}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obj_func(params):\n",
    "    print('Training with params:')\n",
    "    print(params)\n",
    "    \n",
    "    mean_mae , score_std = run_model(xgb.XGBRegressor(**xgb_params),feats)\n",
    "    \n",
    "    return {'loss':np.abs(mean_mae),'status':STATUS_OK}\n",
    "\n",
    "xgb_reg_params={\n",
    "    'learning_rate':    hp.choice('learning_rate', np.arange(0.05,0.31,0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',     np.arange(5,16,1,dtype=int)),\n",
    "    'subsample':        hp.quniform('subsample',0.5,1,0.05),   \n",
    "    'colsample_bytree':  hp.quniform('colsample_bytree',0.5,1,0.05),\n",
    "    'objective':        'reg:squarederror',\n",
    "    'n_estimators':     100,\n",
    "    'seed':0,}\n",
    "best = fmin(obj_func,xgb_reg_params,algo=tpe.suggest,max_evals=25)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.25, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.55, 'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.05, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.2, 'max_depth': 12, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.65, 'learning_rate': 0.2, 'max_depth': 14, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.15000000000000002, 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.25, 'max_depth': 8, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 13, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.75}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.75}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.25, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.75}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.25, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'learning_rate': 0.25, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.25, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.2, 'max_depth': 12, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.25, 'max_depth': 10, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.55, 'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 1.0}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 14, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.25, 'max_depth': 6, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8500000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.1, 'max_depth': 13, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.75}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.65, 'learning_rate': 0.25, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.25, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8500000000000001, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 12, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.8}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.9}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.65, 'learning_rate': 0.25, 'max_depth': 7, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.65}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.25, 'max_depth': 14, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.6000000000000001}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 11, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.55}\n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.75, 'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 100, 'objective': 'reg:squarederror', 'seed': 0, 'subsample': 0.5}\n",
      "100%|██████████████████████████████████████████████████| 50/50 [11:45<00:00, 14.11s/trial, best loss: 9618.08167109244]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8500000000000001,\n",
       " 'learning_rate': 4,\n",
       " 'max_depth': 5,\n",
       " 'subsample': 0.6000000000000001}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obj_func(params):\n",
    "    print('Training with params:')\n",
    "    print(params)\n",
    "    \n",
    "    mean_mae , score_std = run_model(xgb.XGBRegressor(**xgb_params),feats)\n",
    "    \n",
    "    return {'loss':np.abs(mean_mae),'status':STATUS_OK}\n",
    "\n",
    "xgb_reg_params={\n",
    "    'learning_rate':    hp.choice('learning_rate', np.arange(0.05,0.31,0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',     np.arange(5,16,1,dtype=int)),\n",
    "    'subsample':        hp.quniform('subsample',0.5,1,0.05),   \n",
    "    'colsample_bytree':  hp.quniform('colsample_bytree',0.5,1,0.05),\n",
    "    'objective':        'reg:squarederror',\n",
    "    'n_estimators':     100,\n",
    "    'seed':0,}\n",
    "best = fmin(obj_func,xgb_reg_params,algo=tpe.suggest,max_evals=50)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.2376552477165094e+28, 8.560970975533546e+25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params={\n",
    "        'n_estimators':50,\n",
    "        'colsample_bytree': 0.8500000000000001,\n",
    "        'learning_rate': 4,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.6000000000000001\n",
    "}\n",
    "run_model(xgb.XGBRegressor(**xgb_params),feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11475.08530472996, 164.11129655574533)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params={'colsample_bytree': 0.75,\n",
    " 'learning_rate': 1,\n",
    " 'max_depth': 6,\n",
    " 'subsample': 0.55,\n",
    " 'max_depth': 5,\n",
    " 'n_estimators':50,}\n",
    "run_model(xgb.XGBRegressor(**xgb_params),feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
